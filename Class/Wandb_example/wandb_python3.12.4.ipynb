{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:nio07xt2) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64c0e470eb94d75bfcb59d6085b6716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">swift-puddle-1</strong> at: <a href='https://wandb.ai/talktalk/my-awsome-project/runs/nio07xt2' target=\"_blank\">https://wandb.ai/talktalk/my-awsome-project/runs/nio07xt2</a><br/> View project at: <a href='https://wandb.ai/talktalk/my-awsome-project' target=\"_blank\">https://wandb.ai/talktalk/my-awsome-project</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240721_170256-nio07xt2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:nio07xt2). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa35d7f253e8458089eacfcbc367f3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\seowoo kim\\Desktop\\deeplearning\\wandb\\run-20240721_170338-8evsr41j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/talktalk/my-awsome-project/runs/8evsr41j' target=\"_blank\">vital-microwave-2</a></strong> to <a href='https://wandb.ai/talktalk/my-awsome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/talktalk/my-awsome-project' target=\"_blank\">https://wandb.ai/talktalk/my-awsome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/talktalk/my-awsome-project/runs/8evsr41j' target=\"_blank\">https://wandb.ai/talktalk/my-awsome-project/runs/8evsr41j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project = \"my-awsome-project\",\n",
    "    config = {\n",
    "        \"layer_1\": 512,\n",
    "        \"activation_1\": \"relu\",\n",
    "        \"dropout\": random.uniform(0.01, 0.80),\n",
    "        \"layer_2\": 10,\n",
    "        \"activation_2\": \"softmax\",\n",
    "        \"optimizer\": \"sgd\",\n",
    "        \"loss\": \"sparse_categorical_crossentropy\",\n",
    "        \"metric\": \"accuracy\",\n",
    "        \"epoch\": 8,\n",
    "        \"batch_size\": 16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "class WandbCustomCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        wandb.log(logs, step = epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = run.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 ━━━━━━━━━━━━━━━━━━━━ 0s 0s/ste ━━━━━━━━━━━━━━━━━━━━ 54s 5us/ste ━━━━━━━━━━━━━━━━━━━━ 38s 3us/ste ━━━━━━━━━━━━━━━━━━━━ 49s 4us/ste ━━━━━━━━━━━━━━━━━━━━ 47s 4us/ste ━━━━━━━━━━━━━━━━━━━━ 39s 3us/ste ━━━━━━━━━━━━━━━━━━━━ 1:01 5us/st ━━━━━━━━━━━━━━━━━━━━ 35s 3us/step ━━━━━━━━━━━━━━━━━━━━ 29s 3us/ste ━━━━━━━━━━━━━━━━━━━━ 27s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 25s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 23s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 31s 3us/ste ━━━━━━━━━━━━━━━━━━━━ 30s 3us/ste ━━━━━━━━━━━━━━━━━━━━ 31s 3us/ste ━━━━━━━━━━━━━━━━━━━━ 27s 3us/ste ━━━━━━━━━━━━━━━━━━━━ 26s 3us/ste ━━━━━━━━━━━━━━━━━━━━ 25s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 24s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 27s 3us/ste ━━━━━━━━━━━━━━━━━━━━ 26s 3us/ste ━━━━━━━━━━━━━━━━━━━━ 24s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 24s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 23s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 21s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 24s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 22s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 22s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 21s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 22s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 20s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 20s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 18s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 17s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 16s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 15s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 15s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 15s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 14s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 14s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 14s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 13s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 13s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 12s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 12s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 12s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 12s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 12s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 13s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 12s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 12s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 11s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 11s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 11s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 11s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 11s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 11s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 11s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 11s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 11s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 10s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 10s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 10s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 10s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 10s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 10s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 10s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 10s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 10s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 9s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 10s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 9s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 8s 2us/st ━━━━━━━━━━━━━━━━━━━━ 8s 2us/st ━━━━━━━━━━━━━━━━━━━━ 8s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 9s 2us/st ━━━━━━━━━━━━━━━━━━━━ 8s 2us/st ━━━━━━━━━━━━━━━━━━━━ 8s 2us/st ━━━━━━━━━━━━━━━━━━━━ 8s 2us/st ━━━━━━━━━━━━━━━━━━━━ 8s 2us/st ━━━━━━━━━━━━━━━━━━━━ 8s 2us/st ━━━━━━━━━━━━━━━━━━━━ 8s 2us/st ━━━━━━━━━━━━━━━━━━━━ 8s 2us/st ━━━━━━━━━━━━━━━━━━━━ 8s 2us/st ━━━━━━━━━━━━━━━━━━━━ 8s 2us/st ━━━━━━━━━━━━━━━━━━━━ 7s 2us/st ━━━━━━━━━━━━━━━━━━━━ 7s 2us/st ━━━━━━━━━━━━━━━━━━━━ 8s 2us/st ━━━━━━━━━━━━━━━━━━━━ 7s 2us/st ━━━━━━━━━━━━━━━━━━━━ 7s 2us/st ━━━━━━━━━━━━━━━━━━━━ 7s 2us/st ━━━━━━━━━━━━━━━━━━━━ 7s 2us/st ━━━━━━━━━━━━━━━━━━━━ 7s 2us/st ━━━━━━━━━━━━━━━━━━━━ 6s 2us/st ━━━━━━━━━━━━━━━━━━━━ 6s 2us/st ━━━━━━━━━━━━━━━━━━━━ 6s 2us/st ━━━━━━━━━━━━━━━━━━━━ 6s 2us/st ━━━━━━━━━━━━━━━━━━━━ 6s 2us/st ━━━━━━━━━━━━━━━━━━━━ 5s 2us/st ━━━━━━━━━━━━━━━━━━━━ 5s 2us/st ━━━━━━━━━━━━━━━━━━━━ 5s 2us/st ━━━━━━━━━━━━━━━━━━━━ 5s 2us/st ━━━━━━━━━━━━━━━━━━━━ 5s 2us/st ━━━━━━━━━━━━━━━━━━━━ 4s 2us/st ━━━━━━━━━━━━━━━━━━━━ 4s 2us/st ━━━━━━━━━━━━━━━━━━━━ 4s 2us/st ━━━━━━━━━━━━━━━━━━━━ 4s 2us/st ━━━━━━━━━━━━━━━━━━━━ 3s 2us/st ━━━━━━━━━━━━━━━━━━━━ 3s 2us/st ━━━━━━━━━━━━━━━━━━━━ 3s 2us/st ━━━━━━━━━━━━━━━━━━━━ 3s 2us/st ━━━━━━━━━━━━━━━━━━━━ 3s 2us/st ━━━━━━━━━━━━━━━━━━━━ 2s 2us/st ━━━━━━━━━━━━━━━━━━━━ 2s 2us/st ━━━━━━━━━━━━━━━━━━━━ 2s 2us/st ━━━━━━━━━━━━━━━━━━━━ 2s 2us/st ━━━━━━━━━━━━━━━━━━━━ 2s 2us/st ━━━━━━━━━━━━━━━━━━━━ 2s 2us/st ━━━━━━━━━━━━━━━━━━━━ 1s 2us/st ━━━━━━━━━━━━━━━━━━━━ 1s 1us/st ━━━━━━━━━━━━━━━━━━━━ 1s 1us/st ━━━━━━━━━━━━━━━━━━━━ 1s 1us/st ━━━━━━━━━━━━━━━━━━━━ 0s 1us/st ━━━━━━━━━━━━━━━━━━━━ 0s 1us/st ━━━━━━━━━━━━━━━━━━━━ 0s 1us/st ━━━━━━━━━━━━━━━━━━━━ 0s 1us/st ━━━━━━━━━━━━━━━━━━━━ 0s 1us/st ━━━━━━━━━━━━━━━━━━━━ 16s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train, y_train = x_train[::5], y_train[::5]\n",
    "x_test, y_test = x_test[::20], y_test[::20]\n",
    "labels = [str(digit) for digit in range(np.max(y_train)+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seowoo kim\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "        tf.keras.layers.Dense(config.layer_1, activation = config.activation_1),\n",
    "        tf.keras.layers.Dropout(config.dropout),\n",
    "        tf.keras.layers.Dense(config.layer_2, activation = config.activation_2)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = config.optimizer, loss = config.loss, metrics = [config.metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "750/750 ━━━━━━━━━━━━━━━━━━━━ 4:59 400ms/step - accuracy: 0.1250 - loss: 2.35 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.1962 - loss: 2.2353   ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.2268 - loss: 2.19 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.3020 - loss: 2.10 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.3861 - loss: 1.97 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.4428 - loss: 1.87 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.4838 - loss: 1.78 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.5142 - loss: 1.71 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.5424 - loss: 1.64 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.5622 - loss: 1.58 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.5789 - loss: 1.54 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.5922 - loss: 1.50 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.6069 - loss: 1.45 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.6130 - loss: 1.43 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.6246 - loss: 1.40 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.6359 - loss: 1.36 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.6398 - loss: 1.3552 - val_accuracy: 0.8640 - val_loss: 0.5101\n",
      "Epoch 2/8\n",
      "750/750 ━━━━━━━━━━━━━━━━━━━━ 12s 17ms/step - accuracy: 0.9375 - loss: 0.37 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.8836 - loss: 0.4641 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8841 - loss: 0.47 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8826 - loss: 0.48 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8825 - loss: 0.47 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8814 - loss: 0.47 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8807 - loss: 0.47 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8804 - loss: 0.47 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8803 - loss: 0.47 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8803 - loss: 0.47 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8803 - loss: 0.46 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8805 - loss: 0.46 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8807 - loss: 0.46 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8809 - loss: 0.46 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8811 - loss: 0.46 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8815 - loss: 0.45 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.8815 - loss: 0.4581 - val_accuracy: 0.8780 - val_loss: 0.3981\n",
      "Epoch 3/8\n",
      "750/750 ━━━━━━━━━━━━━━━━━━━━ 11s 15ms/step - accuracy: 0.8750 - loss: 0.36 ━━━━━━━━━━━━━━━━━━━━ 0s 978us/step - accuracy: 0.8842 - loss: 0.39 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8830 - loss: 0.4032 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8849 - loss: 0.40 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8871 - loss: 0.39 ━━━━━━━━━━━━━━━━━━━━ 0s 985us/step - accuracy: 0.8889 - loss: 0.39 ━━━━━━━━━━━━━━━━━━━━ 0s 957us/step - accuracy: 0.8902 - loss: 0.38 ━━━━━━━━━━━━━━━━━━━━ 0s 933us/step - accuracy: 0.8916 - loss: 0.38 ━━━━━━━━━━━━━━━━━━━━ 0s 915us/step - accuracy: 0.8928 - loss: 0.38 ━━━━━━━━━━━━━━━━━━━━ 0s 911us/step - accuracy: 0.8938 - loss: 0.38 ━━━━━━━━━━━━━━━━━━━━ 0s 919us/step - accuracy: 0.8946 - loss: 0.37 ━━━━━━━━━━━━━━━━━━━━ 0s 967us/step - accuracy: 0.8949 - loss: 0.37 ━━━━━━━━━━━━━━━━━━━━ 0s 953us/step - accuracy: 0.8957 - loss: 0.37 ━━━━━━━━━━━━━━━━━━━━ 0s 946us/step - accuracy: 0.8964 - loss: 0.37 ━━━━━━━━━━━━━━━━━━━━ 1s 990us/step - accuracy: 0.8969 - loss: 0.3731 - val_accuracy: 0.8900 - val_loss: 0.3598\n",
      "Epoch 4/8\n",
      "750/750 ━━━━━━━━━━━━━━━━━━━━ 13s 18ms/step - accuracy: 0.9375 - loss: 0.20 ━━━━━━━━━━━━━━━━━━━━ 0s 951us/step - accuracy: 0.9095 - loss: 0.29 ━━━━━━━━━━━━━━━━━━━━ 0s 908us/step - accuracy: 0.9040 - loss: 0.31 ━━━━━━━━━━━━━━━━━━━━ 0s 878us/step - accuracy: 0.9038 - loss: 0.32 ━━━━━━━━━━━━━━━━━━━━ 0s 853us/step - accuracy: 0.9051 - loss: 0.32 ━━━━━━━━━━━━━━━━━━━━ 0s 852us/step - accuracy: 0.9066 - loss: 0.31 ━━━━━━━━━━━━━━━━━━━━ 0s 940us/step - accuracy: 0.9072 - loss: 0.31 ━━━━━━━━━━━━━━━━━━━━ 0s 926us/step - accuracy: 0.9082 - loss: 0.31 ━━━━━━━━━━━━━━━━━━━━ 0s 912us/step - accuracy: 0.9087 - loss: 0.31 ━━━━━━━━━━━━━━━━━━━━ 0s 905us/step - accuracy: 0.9092 - loss: 0.31 ━━━━━━━━━━━━━━━━━━━━ 0s 905us/step - accuracy: 0.9095 - loss: 0.31 ━━━━━━━━━━━━━━━━━━━━ 0s 907us/step - accuracy: 0.9097 - loss: 0.31 ━━━━━━━━━━━━━━━━━━━━ 0s 906us/step - accuracy: 0.9099 - loss: 0.31 ━━━━━━━━━━━━━━━━━━━━ 0s 904us/step - accuracy: 0.9101 - loss: 0.31 ━━━━━━━━━━━━━━━━━━━━ 1s 947us/step - accuracy: 0.9101 - loss: 0.3184 - val_accuracy: 0.9120 - val_loss: 0.3296\n",
      "Epoch 5/8\n",
      "750/750 ━━━━━━━━━━━━━━━━━━━━ 11s 16ms/step - accuracy: 0.9375 - loss: 0.29 ━━━━━━━━━━━━━━━━━━━━ 0s 960us/step - accuracy: 0.9198 - loss: 0.31 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9195 - loss: 0.3094 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9194 - loss: 0.30 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9188 - loss: 0.30 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9186 - loss: 0.30 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9186 - loss: 0.30 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9184 - loss: 0.30 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9185 - loss: 0.30 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9186 - loss: 0.30 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9186 - loss: 0.30 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9188 - loss: 0.30 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9189 - loss: 0.30 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9190 - loss: 0.29 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9191 - loss: 0.29 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9192 - loss: 0.29 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9193 - loss: 0.29 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.9193 - loss: 0.2986 - val_accuracy: 0.9000 - val_loss: 0.3238\n",
      "Epoch 6/8\n",
      "750/750 ━━━━━━━━━━━━━━━━━━━━ 11s 15ms/step - accuracy: 1.0000 - loss: 0.10 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9599 - loss: 0.1981 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9479 - loss: 0.21 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9427 - loss: 0.22 ━━━━━━━━━━━━━━━━━━━━ 0s 988us/step - accuracy: 0.9397 - loss: 0.23 ━━━━━━━━━━━━━━━━━━━━ 0s 965us/step - accuracy: 0.9375 - loss: 0.23 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9362 - loss: 0.2424 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9352 - loss: 0.24 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9344 - loss: 0.24 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9335 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9327 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9321 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9317 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9313 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9310 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9307 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.9305 - loss: 0.2585 - val_accuracy: 0.9080 - val_loss: 0.2958\n",
      "Epoch 7/8\n",
      "750/750 ━━━━━━━━━━━━━━━━━━━━ 11s 15ms/step - accuracy: 0.7500 - loss: 0.63 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - accuracy: 0.8968 - loss: 0.3432 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9293 - loss: 0.27 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9359 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9381 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9395 - loss: 0.24 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9403 - loss: 0.24 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9401 - loss: 0.24 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9393 - loss: 0.24 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9386 - loss: 0.24 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9379 - loss: 0.24 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9372 - loss: 0.24 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9369 - loss: 0.24 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9365 - loss: 0.24 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9360 - loss: 0.24 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9357 - loss: 0.24 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9354 - loss: 0.24 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.9353 - loss: 0.2473 - val_accuracy: 0.9100 - val_loss: 0.2869\n",
      "Epoch 8/8\n",
      "750/750 ━━━━━━━━━━━━━━━━━━━━ 11s 15ms/step - accuracy: 0.9375 - loss: 0.16 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9348 - loss: 0.2092 ━━━━━━━━━━━━━━━━━━━━ 0s 964us/step - accuracy: 0.9364 - loss: 0.21 ━━━━━━━━━━━━━━━━━━━━ 0s 939us/step - accuracy: 0.9374 - loss: 0.21 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9372 - loss: 0.2201 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9365 - loss: 0.22 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9362 - loss: 0.22 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9358 - loss: 0.22 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9356 - loss: 0.22 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9355 - loss: 0.22 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9355 - loss: 0.22 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9354 - loss: 0.22 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9353 - loss: 0.23 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9351 - loss: 0.23 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9351 - loss: 0.23 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9350 - loss: 0.23 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.9350 - loss: 0.2311 - val_accuracy: 0.9140 - val_loss: 0.2811\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    epochs=config.epoch,\n",
    "    batch_size=config.batch_size,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[WandbCustomCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa23ef79f0114971aeb5909b5a3ba64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇███</td></tr><tr><td>loss</td><td>█▃▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅█▆▇▇█</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.93358</td></tr><tr><td>loss</td><td>0.23541</td></tr><tr><td>val_accuracy</td><td>0.914</td></tr><tr><td>val_loss</td><td>0.28106</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vital-microwave-2</strong> at: <a href='https://wandb.ai/talktalk/my-awsome-project/runs/8evsr41j' target=\"_blank\">https://wandb.ai/talktalk/my-awsome-project/runs/8evsr41j</a><br/> View project at: <a href='https://wandb.ai/talktalk/my-awsome-project' target=\"_blank\">https://wandb.ai/talktalk/my-awsome-project</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240721_170338-8evsr41j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
