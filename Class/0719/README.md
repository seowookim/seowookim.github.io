ğŸ”‘ **PRT(Peer Review Template)**  
ì‘ì„±ì: ê¹€ë‚˜ê²½ 


- [x]  **1. ì£¼ì–´ì§„ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì™„ì„±ëœ ì½”ë“œê°€ ì œì¶œë˜ì—ˆë‚˜ìš”? (ì™„ì„±ë„)**
    - ë¬¸ì œì—ì„œ ìš”êµ¬í•˜ëŠ” ìµœì¢… ê²°ê³¼ë¬¼ì´ ì²¨ë¶€ë˜ì—ˆëŠ”ì§€ í™•ì¸
    - ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì™„ì„±ëœ ì½”ë“œë€ í”„ë¡œì íŠ¸ ë£¨ë¸Œë¦­ 3ê°œ ì¤‘ 2ê°œ, 
    í€˜ìŠ¤íŠ¸ ë¬¸ì œ ìš”êµ¬ì¡°ê±´ ë“±ì„ ì§€ì¹­
        - í•´ë‹¹ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë¶€ë¶„ì˜ ì½”ë“œ ë° ê²°ê³¼ë¬¼ì„ ìº¡ì³í•˜ì—¬ ì‚¬ì§„ìœ¼ë¡œ ì²¨ë¶€
          1. ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ì •ìƒì ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ê³ , ì‘ë™í•˜ëŠ” ê²ƒì„ í™•ì¸í•˜ì˜€ë‹¤.
            ![image](https://github.com/user-attachments/assets/b46d3ddd-48c7-487f-b528-72167cdd00b5)
            ![image](https://github.com/user-attachments/assets/679bc0ab-11bb-4ff9-b5ff-c78bf2e0f527)
            > ì•Œë§ì€ ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ì˜ ë¶ˆëŸ¬ì˜´

          2. Preprocessingì„ ê°œì„ í•˜ê³ , fine-tuningì„ í†µí•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê°œì„ ì‹œì¼°ë‹¤.	
             ![image](https://github.com/user-attachments/assets/428bb03d-93f6-44a3-b16d-85a90f81615e)
             > ì •í™•ë„ 90%ì€ ë‹¬ì„±í•˜ì§€ ëª»

          4. ëª¨ë¸ í•™ìŠµì— Bucketingì„ ì„±ê³µì ìœ¼ë¡œ ì ìš©í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ë¹„êµë¶„ì„í•˜ì˜€ë‹¤.
             ```
             from transformers import DataCollatorWithPadding

             data_collator = DataCollatorWithPadding(tokenizer=huggingface_tokenizer, padding=True)
             ```
             ```
             training_arguments = TrainingArguments(output_dir, evaluation_strategy = "epoch", learning_rate = 2e-5, group_by_length=True,
                                      per_device_train_batch_size = 8, per_device_eval_batch_size = 8, num_train_epochs = 3, 
                                      weight_decay = 0.01)
             ```
             ```
             trainer = Trainer(model = huggingface_model, args = training_arguments, train_dataset = train_dataset_2, eval_dataset = test_dataset_2, data_collator = data_collator, compute_metrics = compute_metrics) 
             trainer.train()
             ```
             > `DataCollatorWithPadding`ì™€ `group_by_length` ì˜µì…˜ì´ ì˜ ì ìš©ë¨
- [x]  **2. í”„ë¡œì íŠ¸ì—ì„œ í•µì‹¬ì ì¸ ë¶€ë¶„ì— ëŒ€í•œ ì„¤ëª…ì´ ì£¼ì„(ë‹¥ìŠ¤íŠ¸ë§) ë° ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì˜ ê¸°ë¡ë˜ì–´ìˆë‚˜ìš”? (ì„¤ëª…)**
    - [ ]  ëª¨ë¸ ì„ ì • ì´ìœ 
    - [ ]  Metrics ì„ ì • ì´ìœ 
    - [í•´ë‹¹ ì—†ìŒ]  Loss ì„ ì • ì´ìœ 
      ![image](https://github.com/user-attachments/assets/60e4f919-7ea7-4bed-9840-4092cccd599b)
      > ë‹¨ê³„ ë³„ë¡œ ë§ˆí¬ë‹¤ìš´ì´ ì˜ ì í˜€ ìˆìŒ


- [x]  **3. ì²´í¬ë¦¬ìŠ¤íŠ¸ì— í•´ë‹¹í•˜ëŠ” í•­ëª©ë“¤ì„ ëª¨ë‘ ìˆ˜í–‰í•˜ì˜€ë‚˜ìš”? (ë¬¸ì œ í•´ê²°)**
    - [x]  ë°ì´í„°ë¥¼ ë¶„í• í•˜ì—¬ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í–ˆë‚˜ìš”? (train, validation, test ë°ì´í„°ë¡œ êµ¬ë¶„)
          ![image](https://github.com/user-attachments/assets/966945f1-e35c-45d9-9b1c-6b535c5c436d)
          > ë°ì´í„°ë¥¼ ë¶„í• í•˜ì˜€ìœ¼ë©° í•™ìŠµ ì‹œê°„ ì¡°ì ˆì„ ìœ„í•´ ì¼ë¶€ë§Œ ì‚¬ìš©
    - [x]  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ë³€ê²½í•´ê°€ë©° ì—¬ëŸ¬ ì‹œë„ë¥¼ í–ˆë‚˜ìš”? (learning rate, dropout rate, unit, batch size, epoch ë“±)
          ![image](https://github.com/user-attachments/assets/671a2efa-7236-48f5-8dd1-2548dc1411c8)
          > í† í°í™”ì—ì„œ max_lengthë¥¼ ë³€ê²½í•´ê°€ë©° ì‹œë„í•¨
    - [ ]  ê° ì‹¤í—˜ì„ ì‹œê°í™”í•˜ì—¬ ë¹„êµí•˜ì˜€ë‚˜ìš”?
    - [x]  ëª¨ë“  ì‹¤í—˜ ê²°ê³¼ê°€ ê¸°ë¡ë˜ì—ˆë‚˜ìš”?
          ![image](https://github.com/user-attachments/assets/6051f481-bc48-4172-bc1c-3a86236175fe)
         > ì‹¤í—˜ ë³„, epoch ë³„ë¡œ lossì™€ accuracy, F1 scoreê°€ ì˜ ê¸°ë¡ë¨


- [x]  **4. í”„ë¡œì íŠ¸ì— ëŒ€í•œ íšŒê³ ê°€ ìƒì„¸íˆ ê¸°ë¡ ë˜ì–´ ìˆë‚˜ìš”? (íšŒê³ , ì •ë¦¬)**
    - [x]  ë°°ìš´ ì 
    - [x]  ì•„ì‰¬ìš´ ì 
    - [x]  ëŠë‚€ ì 
    - [ ]  ì–´ë ¤ì› ë˜ ì 
    ![image](https://github.com/user-attachments/assets/bd2323ee-3a31-4248-947d-d13efc119f0f)
